{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pix2pix denoising.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "private_outputs": true,
      "authorship_tag": "ABX9TyM7AGxzuuLp9Brhzjg2YCw2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RossM/pix2pix-denoising-colab/blob/main/pix2pix_denoising.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "IfXEFmRvYdmy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GPU status"
      ],
      "metadata": {
        "id": "Qv1x14G-ZjeY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "simple_nvidia_smi_display = False#@param {type:\"boolean\"}\n",
        "if simple_nvidia_smi_display:\n",
        "    #!nvidia-smi\n",
        "    nvidiasmi_output = subprocess.run(['nvidia-smi', '-L'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    print(nvidiasmi_output)\n",
        "else:\n",
        "    #!nvidia-smi -i 0 -e 0\n",
        "    nvidiasmi_output = subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    print(nvidiasmi_output)\n",
        "    nvidiasmi_ecc_note = subprocess.run(['nvidia-smi', '-i', '0', '-e', '0'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    print(nvidiasmi_ecc_note)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "WIdM1Kn3YcPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up Google Drive"
      ],
      "metadata": {
        "id": "DoExgck_ZZBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4TGsnF08aWc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download the data"
      ],
      "metadata": {
        "id": "jakoyk_jZWH3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwvZkapDUhlJ"
      },
      "outputs": [],
      "source": [
        "DATA_DIR = \"/content/danbooru2021/images\"\n",
        "\n",
        "!mkdir -p $DATA_DIR\n",
        "!rsync --progress --recursive --size-only --verbose rsync://176.9.41.242:873/danbooru2021/512px/000*/ $DATA_DIR/512px/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install dependencies"
      ],
      "metadata": {
        "id": "pq_PSpPyZT8M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dominate wandb torchvision einops realesrgan denoising-diffusion-pytorch"
      ],
      "metadata": {
        "id": "dILRNjf-axy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define our model"
      ],
      "metadata": {
        "id": "ZbbGfN5dZQ4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import init\n",
        "from torch.optim import lr_scheduler\n",
        "from denoising_diffusion_pytorch import Unet\n",
        "from realesrgan.archs.discriminator_arch import UNetDiscriminatorSN\n",
        "\n",
        "# Based on code from pytorch-pix2pix https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix\n",
        "\n",
        "def init_weights(net, init_type='normal', init_gain=0.02):\n",
        "    \"\"\"Initialize network weights.\n",
        "\n",
        "    Parameters:\n",
        "        net (network)   -- network to be initialized\n",
        "        init_type (str) -- the name of an initialization method: normal | xavier | kaiming | orthogonal\n",
        "        init_gain (float)    -- scaling factor for normal, xavier and orthogonal.\n",
        "\n",
        "    We use 'normal' in the original pix2pix and CycleGAN paper. But xavier and kaiming might\n",
        "    work better for some applications. Feel free to try yourself.\n",
        "    \"\"\"\n",
        "    def init_func(m):  # define the initialization function\n",
        "        classname = m.__class__.__name__\n",
        "        if hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):\n",
        "            if init_type == 'normal':\n",
        "                init.normal_(m.weight.data, 0.0, init_gain)\n",
        "            elif init_type == 'xavier':\n",
        "                init.xavier_normal_(m.weight.data, gain=init_gain)\n",
        "            elif init_type == 'kaiming':\n",
        "                init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
        "            elif init_type == 'orthogonal':\n",
        "                init.orthogonal_(m.weight.data, gain=init_gain)\n",
        "            else:\n",
        "                raise NotImplementedError('initialization method [%s] is not implemented' % init_type)\n",
        "            if hasattr(m, 'bias') and m.bias is not None:\n",
        "                init.constant_(m.bias.data, 0.0)\n",
        "        elif classname.find('BatchNorm2d') != -1:  # BatchNorm Layer's weight is not a matrix; only normal distribution applies.\n",
        "            init.normal_(m.weight.data, 1.0, init_gain)\n",
        "            init.constant_(m.bias.data, 0.0)\n",
        "\n",
        "    print('initialize network with %s' % init_type)\n",
        "    net.apply(init_func)  # apply the initialization function <init_func>\n",
        "\n",
        "\n",
        "def init_net(net, init_type='normal', init_gain=0.02, gpu_ids=[]):\n",
        "    \"\"\"Initialize a network: 1. register CPU/GPU device (with multi-GPU support); 2. initialize the network weights\n",
        "    Parameters:\n",
        "        net (network)      -- the network to be initialized\n",
        "        init_type (str)    -- the name of an initialization method: normal | xavier | kaiming | orthogonal\n",
        "        gain (float)       -- scaling factor for normal, xavier and orthogonal.\n",
        "        gpu_ids (int list) -- which GPUs the network runs on: e.g., 0,1,2\n",
        "\n",
        "    Return an initialized network.\n",
        "    \"\"\"\n",
        "    if len(gpu_ids) > 0:\n",
        "        assert(torch.cuda.is_available())\n",
        "        net.to(gpu_ids[0])\n",
        "        net = torch.nn.DataParallel(net, gpu_ids)  # multi-GPUs\n",
        "    init_weights(net, init_type, init_gain=init_gain)\n",
        "    return net\n",
        "\n",
        "def get_scheduler(optimizer, opt):\n",
        "    \"\"\"Return a learning rate scheduler\n",
        "\n",
        "    Parameters:\n",
        "        optimizer          -- the optimizer of the network\n",
        "        opt (option class) -- stores all the experiment flags; needs to be a subclass of BaseOptions．　\n",
        "                              opt.lr_policy is the name of learning rate policy: linear | step | plateau | cosine\n",
        "\n",
        "    For 'linear', we keep the same learning rate for the first <opt.n_epochs> epochs\n",
        "    and linearly decay the rate to zero over the next <opt.n_epochs_decay> epochs.\n",
        "    For other schedulers (step, plateau, and cosine), we use the default PyTorch schedulers.\n",
        "    See https://pytorch.org/docs/stable/optim.html for more details.\n",
        "    \"\"\"\n",
        "    def lambda_rule(epoch):\n",
        "        lr_l = 1.0 - max(0, epoch + opt.epoch_count - opt.n_epochs) / float(opt.n_epochs_decay + 1)\n",
        "        return lr_l\n",
        "    scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_rule)\n",
        "    return scheduler\n",
        "\n",
        "\n",
        "##############################################################################\n",
        "# Classes\n",
        "##############################################################################\n",
        "class GANLoss(nn.Module):\n",
        "    \"\"\"Define different GAN objectives.\n",
        "\n",
        "    The GANLoss class abstracts away the need to create the target label tensor\n",
        "    that has the same size as the input.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, gan_mode, target_real_label=1.0, target_fake_label=0.0):\n",
        "        \"\"\" Initialize the GANLoss class.\n",
        "\n",
        "        Parameters:\n",
        "            gan_mode (str) - - the type of GAN objective. It currently supports vanilla, lsgan, and wgangp.\n",
        "            target_real_label (bool) - - label for a real image\n",
        "            target_fake_label (bool) - - label of a fake image\n",
        "\n",
        "        Note: Do not use sigmoid as the last layer of Discriminator.\n",
        "        LSGAN needs no sigmoid. vanilla GANs will handle it with BCEWithLogitsLoss.\n",
        "        \"\"\"\n",
        "        super(GANLoss, self).__init__()\n",
        "        self.register_buffer('real_label', torch.tensor(target_real_label))\n",
        "        self.register_buffer('fake_label', torch.tensor(target_fake_label))\n",
        "        self.gan_mode = gan_mode\n",
        "        if gan_mode == 'lsgan':\n",
        "            self.loss = nn.MSELoss()\n",
        "        elif gan_mode == 'vanilla':\n",
        "            self.loss = nn.BCEWithLogitsLoss()\n",
        "        elif gan_mode in ['wgangp']:\n",
        "            self.loss = None\n",
        "        else:\n",
        "            raise NotImplementedError('gan mode %s not implemented' % gan_mode)\n",
        "\n",
        "    def get_target_tensor(self, prediction, target_is_real):\n",
        "        \"\"\"Create label tensors with the same size as the input.\n",
        "\n",
        "        Parameters:\n",
        "            prediction (tensor) - - tpyically the prediction from a discriminator\n",
        "            target_is_real (bool) - - if the ground truth label is for real images or fake images\n",
        "\n",
        "        Returns:\n",
        "            A label tensor filled with ground truth label, and with the size of the input\n",
        "        \"\"\"\n",
        "\n",
        "        if target_is_real:\n",
        "            target_tensor = self.real_label\n",
        "        else:\n",
        "            target_tensor = self.fake_label\n",
        "        return target_tensor.expand_as(prediction)\n",
        "\n",
        "    def __call__(self, prediction, target_is_real):\n",
        "        \"\"\"Calculate loss given Discriminator's output and grount truth labels.\n",
        "\n",
        "        Parameters:\n",
        "            prediction (tensor) - - tpyically the prediction output from a discriminator\n",
        "            target_is_real (bool) - - if the ground truth label is for real images or fake images\n",
        "\n",
        "        Returns:\n",
        "            the calculated loss.\n",
        "        \"\"\"\n",
        "        if self.gan_mode in ['lsgan', 'vanilla']:\n",
        "            target_tensor = self.get_target_tensor(prediction, target_is_real)\n",
        "            loss = self.loss(prediction, target_tensor)\n",
        "        elif self.gan_mode == 'wgangp':\n",
        "            if target_is_real:\n",
        "                loss = -prediction.mean()\n",
        "            else:\n",
        "                loss = prediction.mean()\n",
        "        return loss\n",
        "\n",
        "class Pix2PixModel:\n",
        "    \"\"\" This class implements the pix2pix model, for learning a mapping from input images to output images given paired data.\n",
        "\n",
        "    The model training requires '--dataset_mode aligned' dataset.\n",
        "    By default, it uses a '--netG unet256' U-Net generator,\n",
        "    a '--netD basic' discriminator (PatchGAN),\n",
        "    and a '--gan_mode' vanilla GAN loss (the cross-entropy objective used in the orignal GAN paper).\n",
        "\n",
        "    pix2pix paper: https://arxiv.org/pdf/1611.07004.pdf\n",
        "    \"\"\"\n",
        "    def __init__(self, opt):\n",
        "        \"\"\"Initialize the pix2pix class.\n",
        "\n",
        "        Parameters:\n",
        "            opt (Option class)-- stores all the experiment flags; needs to be a subclass of BaseOptions\n",
        "        \"\"\"\n",
        "        # Base model\n",
        "        self.opt = opt\n",
        "        self.gpu_ids = opt.gpu_ids\n",
        "        self.isTrain = opt.isTrain\n",
        "        self.device = torch.device('cuda:{}'.format(self.gpu_ids[0])) if self.gpu_ids else torch.device('cpu')  # get device name: CPU or GPU\n",
        "        self.save_dir = os.path.join(opt.checkpoints_dir, opt.name)  # save all the checkpoints to save_dir\n",
        "        torch.backends.cudnn.benchmark = True\n",
        "        self.optimizers = []\n",
        "        self.image_paths = []\n",
        "        self.metric = 0  # used for learning rate policy 'plateau'\n",
        "\n",
        "        # specify the training losses you want to print out. The training/test scripts will call <BaseModel.get_current_losses>\n",
        "        self.loss_names = ['G_GAN', 'G_L1', 'D_real', 'D_fake']\n",
        "        # specify the images you want to save/display. The training/test scripts will call <BaseModel.get_current_visuals>\n",
        "        self.visual_names = ['real_A', 'fake_B', 'real_B']\n",
        "        # specify the models you want to save to the disk. The training/test scripts will call <BaseModel.save_networks> and <BaseModel.load_networks>\n",
        "        if self.isTrain:\n",
        "            self.model_names = ['G', 'D']\n",
        "        else:  # during test time, only load G\n",
        "            self.model_names = ['G']\n",
        "        # define networks (both generator and discriminator)\n",
        "        self.netG = Unet(dim=opt.ngf, resnet_block_groups=8)\n",
        "        #self.netG.bfloat16()\n",
        "        self.netG = init_net(self.netG, opt.init_type, opt.init_gain, opt.gpu_ids)\n",
        "\n",
        "        if self.isTrain:  # define a discriminator; conditional GANs need to take both input and output images; Therefore, #channels for D is input_nc + output_nc\n",
        "            #self.netD = Unet(channels=opt.input_nc+opt.output_nc, dim=opt.ndf, resnet_block_groups=4, out_dim=1)\n",
        "            #self.netD.bfloat16()\n",
        "            self.netD = UNetDiscriminatorSN(num_in_ch=opt.input_nc+opt.output_nc, num_feat=opt.ndf)\n",
        "            self.netD = init_net(self.netD, opt.init_type, opt.init_gain, opt.gpu_ids)\n",
        "\n",
        "        if self.isTrain:\n",
        "            # define loss functions\n",
        "            self.criterionGAN = GANLoss(opt.gan_mode).to(self.device)\n",
        "            self.criterionL1 = torch.nn.L1Loss()\n",
        "            self.criterionMSE = torch.nn.MSELoss()\n",
        "            # initialize optimizers; schedulers will be automatically created by function <BaseModel.setup>.\n",
        "            self.optimizer_G = torch.optim.Adam(self.netG.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))\n",
        "            self.optimizer_D = torch.optim.Adam(self.netD.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))\n",
        "            self.optimizers.append(self.optimizer_G)\n",
        "            self.optimizers.append(self.optimizer_D)\n",
        "\n",
        "    def forward(self, time = None):\n",
        "        \"\"\"Run forward pass; called by both functions <optimize_parameters> and <test>.\"\"\"\n",
        "        self.fake_B = self.netG(self.real_A, time)  # G(A)\n",
        "\n",
        "    def backward_D(self, time = None):\n",
        "        \"\"\"Calculate GAN loss for the discriminator\"\"\"\n",
        "        # Fake; stop backprop to the generator by detaching fake_B\n",
        "        fake_AB = torch.cat((self.real_A, self.fake_B), 1)  # we use conditional GANs; we need to feed both input and output to the discriminator\n",
        "        pred_fake = self.netD(fake_AB.detach())\n",
        "        self.loss_D_fake = self.criterionGAN(pred_fake, False)\n",
        "        # Real\n",
        "        real_AB = torch.cat((self.real_A, self.real_B), 1)\n",
        "        pred_real = self.netD(real_AB)\n",
        "        self.loss_D_real = self.criterionGAN(pred_real, True)\n",
        "        # combine loss and calculate gradients\n",
        "        self.loss_D = (self.loss_D_fake + self.loss_D_real) * 0.5\n",
        "        self.loss_D.backward()\n",
        "\n",
        "    def backward_G(self, time = None):\n",
        "        \"\"\"Calculate GAN and L1 loss for the generator\"\"\"\n",
        "        # First, G(A) should fake the discriminator\n",
        "        fake_AB = torch.cat((self.real_A, self.fake_B), 1)\n",
        "        pred_fake = self.netD(fake_AB)\n",
        "        self.loss_G_GAN = self.criterionGAN(pred_fake, True)\n",
        "        # Second, G(A) = B\n",
        "        self.loss_G_L1 = self.criterionL1(self.fake_B, self.real_B) * self.opt.lambda_L1\n",
        "        self.loss_G_MSE = self.criterionMSE(self.fake_B, self.real_B) * self.opt.lambda_MSE\n",
        "        # combine loss and calculate gradients\n",
        "        self.loss_G = self.loss_G_GAN + self.loss_G_L1 + self.loss_G_MSE\n",
        "        self.loss_G.backward()\n",
        "\n",
        "    def optimize_parameters(self, time=None):\n",
        "        #time.bfloat16()\n",
        "        self.forward(time)                   # compute fake images: G(A)\n",
        "        # update D\n",
        "        self.set_requires_grad(self.netD, True)  # enable backprop for D\n",
        "        self.optimizer_D.zero_grad()     # set D's gradients to zero\n",
        "        self.backward_D(time)                # calculate gradients for D\n",
        "        self.optimizer_D.step()          # update D's weights\n",
        "        # update G\n",
        "        self.set_requires_grad(self.netD, False)  # D requires no gradients when optimizing G\n",
        "        self.optimizer_G.zero_grad()        # set G's gradients to zero\n",
        "        self.backward_G(time)                   # calculate graidents for G\n",
        "        self.optimizer_G.step()             # udpate G's weights\n",
        "\n",
        "    def setup(self, opt):\n",
        "        \"\"\"Load and print networks; create schedulers\n",
        "\n",
        "        Parameters:\n",
        "            opt (Option class) -- stores all the experiment flags; needs to be a subclass of BaseOptions\n",
        "        \"\"\"\n",
        "        if self.isTrain:\n",
        "            self.schedulers = [get_scheduler(optimizer, opt) for optimizer in self.optimizers]\n",
        "        self.print_networks(opt.verbose)\n",
        "\n",
        "    def eval(self):\n",
        "        \"\"\"Make models eval mode during test time\"\"\"\n",
        "        for name in self.model_names:\n",
        "            if isinstance(name, str):\n",
        "                net = getattr(self, 'net' + name)\n",
        "                net.eval()\n",
        "\n",
        "    def test(self):\n",
        "        \"\"\"Forward function used in test time.\n",
        "\n",
        "        This function wraps <forward> function in no_grad() so we don't save intermediate steps for backprop\n",
        "        It also calls <compute_visuals> to produce additional visualization results\n",
        "        \"\"\"\n",
        "        with torch.no_grad():\n",
        "            self.forward()\n",
        "            self.compute_visuals()\n",
        "\n",
        "    def update_learning_rate(self):\n",
        "        \"\"\"Update learning rates for all the networks; called at the end of every epoch\"\"\"\n",
        "        old_lr = self.optimizers[0].param_groups[0]['lr']\n",
        "        for scheduler in self.schedulers:\n",
        "            scheduler.step()\n",
        "\n",
        "        lr = self.optimizers[0].param_groups[0]['lr']\n",
        "        print('learning rate %.7f -> %.7f' % (old_lr, lr))\n",
        "\n",
        "    def save_networks(self, epoch):\n",
        "        \"\"\"Save all the networks to the disk.\n",
        "\n",
        "        Parameters:\n",
        "            epoch (int) -- current epoch; used in the file name '%s_net_%s.pth' % (epoch, name)\n",
        "        \"\"\"\n",
        "        for name in self.model_names:\n",
        "            if isinstance(name, str):\n",
        "                save_filename = '%s_net_%s.pth' % (epoch, name)\n",
        "                save_path = os.path.join(self.save_dir, save_filename)\n",
        "                net = getattr(self, 'net' + name)\n",
        "\n",
        "                if len(self.gpu_ids) > 0 and torch.cuda.is_available():\n",
        "                    torch.save(net.module.cpu().state_dict(), save_path)\n",
        "                    net.cuda(self.gpu_ids[0])\n",
        "                else:\n",
        "                    torch.save(net.cpu().state_dict(), save_path)\n",
        "\n",
        "    def load_networks(self, epoch):\n",
        "        \"\"\"Load all the networks from the disk.\n",
        "\n",
        "        Parameters:\n",
        "            epoch (int) -- current epoch; used in the file name '%s_net_%s.pth' % (epoch, name)\n",
        "        \"\"\"\n",
        "        for name in self.model_names:\n",
        "            if isinstance(name, str):\n",
        "                load_filename = '%s_net_%s.pth' % (epoch, name)\n",
        "                load_path = os.path.join(self.save_dir, load_filename)\n",
        "                net = getattr(self, 'net' + name)\n",
        "                if isinstance(net, torch.nn.DataParallel):\n",
        "                    net = net.module\n",
        "                print('loading the model from %s' % load_path)\n",
        "                # if you are using PyTorch newer than 0.4 (e.g., built from\n",
        "                # GitHub source), you can remove str() on self.device\n",
        "                state_dict = torch.load(load_path, map_location=str(self.device))\n",
        "                if hasattr(state_dict, '_metadata'):\n",
        "                    del state_dict._metadata\n",
        "\n",
        "                net.load_state_dict(state_dict)\n",
        "\n",
        "    def print_networks(self, verbose):\n",
        "        \"\"\"Print the total number of parameters in the network and (if verbose) network architecture\n",
        "\n",
        "        Parameters:\n",
        "            verbose (bool) -- if verbose: print the network architecture\n",
        "        \"\"\"\n",
        "        print('---------- Networks initialized -------------')\n",
        "        for name in self.model_names:\n",
        "            if isinstance(name, str):\n",
        "                net = getattr(self, 'net' + name)\n",
        "                num_params = 0\n",
        "                for param in net.parameters():\n",
        "                    num_params += param.numel()\n",
        "                if verbose:\n",
        "                    print(net)\n",
        "                print('[Network %s] Total number of parameters : %.3f M' % (name, num_params / 1e6))\n",
        "        print('-----------------------------------------------')\n",
        "\n",
        "    def set_requires_grad(self, nets, requires_grad=False):\n",
        "        \"\"\"Set requies_grad=Fasle for all the networks to avoid unnecessary computations\n",
        "        Parameters:\n",
        "            nets (network list)   -- a list of networks\n",
        "            requires_grad (bool)  -- whether the networks require gradients or not\n",
        "        \"\"\"\n",
        "        if not isinstance(nets, list):\n",
        "            nets = [nets]\n",
        "        for net in nets:\n",
        "            if net is not None:\n",
        "                for param in net.parameters():\n",
        "                    param.requires_grad = requires_grad\n",
        "\n"
      ],
      "metadata": {
        "id": "iyjkOXSqXxld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model configuration"
      ],
      "metadata": {
        "id": "kQotN5mtzBUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainOptions():\n",
        "    pass\n",
        "\n",
        "opt = TrainOptions()\n",
        "opt.checkpoints_dir = '/content/drive/MyDrive/AI/pix2pix/checkpoints'\n",
        "opt.name = \"pix2pix-denoising-4\"\n",
        "\n",
        "# Model parameters. Changing these will invalidate checkpoint files\n",
        "opt.input_nc = opt.output_nc = 3\n",
        "opt.ngf = 96\n",
        "opt.ndf = 128\n",
        "\n",
        "# Training parameters\n",
        "opt.init_type = \"normal\"\n",
        "opt.init_gain = 0.02\n",
        "opt.gan_mode = \"lsgan\"\n",
        "opt.beta1 = 0.5\n",
        "opt.lr = 0.0002\n",
        "opt.epoch_count = 1\n",
        "opt.n_epochs = 100\n",
        "opt.n_epochs_decay = 100\n",
        "opt.lambda_L1 = 0.0\n",
        "opt.lambda_MSE = 100.0\n",
        "opt.verbose = False       #@param {type: 'boolean'}\n",
        "opt.gpu_ids = [0]\n",
        "opt.noise_min = 0.1\n",
        "opt.noise_max = 3.0\n",
        "opt.noise_alpha = 2.0\n",
        "\n",
        "# Input parameters. Changing these may degrade result quality for a few\n",
        "# hundred batches until the model adjusts.\n",
        "opt.noise_schedule_beta = 0.003     # Used for calculating the time passed to the generator\n",
        "opt.use_random_times = False      # Estimates time based on post-noise image statistics\n",
        "opt.clamp_input = False\n"
      ],
      "metadata": {
        "id": "o4iRw1MpzDvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "AlfZaNA3XqY7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math, random\n",
        "import torch\n",
        "import torchvision as tv\n",
        "import einops\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "from torchvision.datasets import ImageFolder\n",
        "from IPython import display\n",
        "\n",
        "torch.cuda.set_device(0)\n",
        "cuda = torch.device('cuda')\n",
        "\n",
        "dataset = tv.datasets.ImageFolder(root = DATA_DIR, \n",
        "  transform = tv.transforms.Compose([\n",
        "    #tv.transforms.Resize(256),                                                            \n",
        "    tv.transforms.ToTensor()\n",
        "  ]))\n",
        "data_loader = torch.utils.data.DataLoader(dataset,\n",
        "                                          batch_size=4,\n",
        "                                          shuffle=True,\n",
        "                                          num_workers=4)\n",
        "\n",
        "\n",
        "opt.isTrain = True\n",
        "opt.continue_train = False\n",
        "\n",
        "RUN_DIR = f\"{opt.checkpoints_dir}/{opt.name}\"\n",
        "!mkdir -p $RUN_DIR\n",
        "\n",
        "model = Pix2PixModel(opt)\n",
        "model.setup(opt)\n",
        "\n",
        "start_epoch = 1\n",
        "last_epoch = 100\n",
        "# Resume\n",
        "try:\n",
        "  cp = open(f\"{opt.checkpoints_dir}/{opt.name}/latest_epoch\", \"r\")\n",
        "  start_epoch = int(cp.read())\n",
        "  model.load_networks(str(start_epoch))\n",
        "  start_epoch += 1\n",
        "  cp.close()\n",
        "except:\n",
        "  pass\n",
        "\n",
        "#display.clear_output(wait=True)\n",
        "#dataset[1000][0]\n",
        "\n",
        "crop = tv.transforms.RandomCrop(256)\n",
        "\n",
        "for epoch in range(start_epoch, last_epoch+1):\n",
        "  model.update_learning_rate()\n",
        "  for i, data in enumerate(data_loader):\n",
        "    output_data = crop(data[0].cuda()) * 2 - 1\n",
        "    stddev = torch.rand(size = (output_data.size()[0], ), device = cuda) ** opt.noise_alpha * (opt.noise_max - opt.noise_min) + opt.noise_min\n",
        "    input_data = (output_data + torch.randn_like(output_data) * einops.rearrange(stddev, 'd -> d 1 1 1'))\n",
        "    if opt.clamp_input:\n",
        "      input_data = input_data.clamp(-1, 1)\n",
        "\n",
        "    model.real_A = input_data\n",
        "    model.real_B = output_data\n",
        "\n",
        "    # Time estimation based on an exponentially decreasing cumulative beta schedule with constant beta\n",
        "    if opt.use_random_times:\n",
        "      time = torch.rand(size = (output_data.size()[0], )) * 1000\n",
        "    else:\n",
        "      time = torch.log(stddev / (1 + stddev)) / math.log(1 - opt.noise_schedule_beta)\n",
        "    model.optimize_parameters(time)\n",
        "\n",
        "    if i % 10 == 0:\n",
        "      display.clear_output(wait=True)\n",
        "      model.print_networks(verbose=opt.verbose)\n",
        "      print(f\"epoch {epoch}/{last_epoch} batch {i}/{len(data_loader)}\")\n",
        "      sample_index = 0\n",
        "      print(f\"Sample {sample_index}: stddev {stddev[sample_index]}, time {time[sample_index]}\")\n",
        "      display.display_png(to_pil_image(torch.cat((model.real_A[0],\n",
        "                                                  model.real_B[0],\n",
        "                                                  model.fake_B[0]), dim=2).clamp(-1, 1) * 0.5 + 0.5))\n",
        "      print(f\"Batch losses: G_GAN {model.loss_G_GAN}, G_L1 {model.loss_G_L1}, G_MSE {model.loss_G_MSE}, D_fake {model.loss_D_fake}, D_real {model.loss_D_real}\")\n",
        "\n",
        "  model.save_networks('latest')\n",
        "  model.save_networks(epoch)\n",
        "  cp = open(f\"{opt.checkpoints_dir}/{opt.name}/latest_epoch\", \"w\")\n",
        "  cp.write(str(epoch))\n",
        "  cp.close()\n"
      ],
      "metadata": {
        "id": "3dNW0jxvb60P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Denoise"
      ],
      "metadata": {
        "id": "cPM77ZOm4uST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math, io, requests\n",
        "import torch\n",
        "import einops\n",
        "from PIL import Image\n",
        "from torchvision.transforms.functional import to_tensor, to_pil_image, resize\n",
        "from IPython import display\n",
        "\n",
        "image_url = \"https://i.imgur.com/3NHuxu1.png\" #@param {type: \"string\"}\n",
        "image_size = [256, 256] #@param {type: \"raw\"}\n",
        "injected_noise =  0.2#@param {type: \"number\"}\n",
        "iterations = 1 #@param {type: \"integer\", min:1}\n",
        "\n",
        "def fetch(url_or_path):\n",
        "    if str(url_or_path).startswith('http://') or str(url_or_path).startswith('https://'):\n",
        "        r = requests.get(url_or_path)\n",
        "        r.raise_for_status()\n",
        "        fd = io.BytesIO()\n",
        "        fd.write(r.content)\n",
        "        fd.seek(0)\n",
        "        return fd\n",
        "    return open(url_or_path, 'rb')\n",
        "\n",
        "torch.cuda.set_device(0)\n",
        "cuda = torch.device('cuda')\n",
        "\n",
        "opt.isTrain = False\n",
        "\n",
        "model = Pix2PixModel(opt)\n",
        "model.setup(opt)\n",
        "model.load_networks('latest')\n",
        "\n",
        "if image_url != \"\":\n",
        "  pil_image = Image.open(fetch(image_url)).convert('RGB')\n",
        "\n",
        "  print(\"Input image\")\n",
        "  display.display_png(pil_image)\n",
        "\n",
        "  if image_size != None:\n",
        "    pil_image = resize(pil_image, image_size)\n",
        "  image = to_tensor(pil_image).to(model.device)\n",
        "  image = einops.rearrange(image, '... -> 1 ...')\n",
        "  image = image * 2 - 1\n",
        "else:\n",
        "  if image_size == None:\n",
        "    image_size = [256, 256]\n",
        "  image = torch.zeros(1, 3, image_size[0], image_size[1]).to(model.device)\n",
        "\n",
        "image += torch.randn_like(image) * injected_noise\n",
        "if opt.clamp_input:\n",
        "  image = image.clamp(-1, 1)\n",
        "\n",
        "model.set_requires_grad(model.netG, False)\n",
        "\n",
        "if opt.use_random_times:\n",
        "  time = torch.rand(size = (output_data.size()[0], )) * 1000\n",
        "else:\n",
        "  time = torch.log(injected_noise / (1 + injected_noise)) / math.log(1 - opt.noise_schedule_beta)\n",
        "\n",
        "for step in range(0, iterations):\n",
        "  t = step / iterations\n",
        "\n",
        "  iter = model.netG(image, time)\n",
        "  image = image + (iter - image) / (iterations - step)\n",
        "\n",
        "  if step + 1 < iterations:\n",
        "    print(f\"Iteration {step+1}/{iterations}\")\n",
        "    display.display_png(to_pil_image(iter[0].clamp(-1, 1) * 0.5 + 0.5))\n",
        "\n",
        "print(\"Final result\")\n",
        "display.display_png(to_pil_image(image[0].clamp(-1, 1) * 0.5 + 0.5))\n"
      ],
      "metadata": {
        "id": "6fVpqu5u4vlk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}